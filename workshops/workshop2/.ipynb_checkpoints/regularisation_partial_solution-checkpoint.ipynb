{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adammoss/MLiS2/blob/master/workshops/workshop2/regularisation_partial_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. \n",
    "\n",
    "We have:  \n",
    "$ J(\\mathbf{w}) = (\\mathbf{Xw} - \\mathbf{Y})^T (\\mathbf{Xw} - \\mathbf{Y}) + \\lambda||\\mathbf{w}||_2^2 $\n",
    "\n",
    "To find the optimal weights, we need to solve the normal set of equations i.e.  \n",
    "$ \\bigtriangledown_\\mathbf{w} J(\\mathbf{w}) = 0$\n",
    "\n",
    "or  \n",
    "$\\frac{\\partial}{\\partial \\mathbf{w}} J(\\mathbf{w}) = \\frac{\\partial}{\\partial \\mathbf{w}} \\left{(\\mathbf{Xw} - \\mathbf{Y})^T (\\mathbf{Xw} - \\mathbf{Y}) + \\lambda||\\mathbf{w}||_2^2 = 0 \\right}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9lgu7n44eFs"
   },
   "source": [
    "**Regularisation**\n",
    "\n",
    "In this example you are given a dataset (MNIST) with a limited number of training examples (only 1000 compared to the usual 60,000). \n",
    "\n",
    "Your goal is to implement regularisation methods to achive the **lowest possible test loss using this dataset**. \n",
    "\n",
    "You should consider methods given in the lectures including:\n",
    "\n",
    "*   Data augmentation\n",
    "*   Early stopping\n",
    "*   L1/L2 penalty norms\n",
    "*   Dropout\n",
    "\n",
    "You are free to change the network architecture and model complexity, but the main purpose of the workshop is to investigate regularisation (next week you will look at CNN architectures in detail). \n",
    "\n",
    "You are also free to change the choice of optimiser, and other hyper-parameters such as the batch size.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cNviuTwum6vs"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARZRYjHQnE-0"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7I-MxTxAnH2d"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cxO576eJnMXN",
    "outputId": "eb69b506-508e-4b1c-8ab6-7238df87c2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4F_HTQpnvSk"
   },
   "source": [
    "First load the MNIST dataset and add a channels dimension (channels last convention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Twdc-t9FnN_9"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
    "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
    "\n",
    "img_rows = x_train.shape[1]\n",
    "img_cols = x_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEsWYkNz5Po7"
   },
   "source": [
    "Let's use a much smaller training dataset of 1000 examples so overfitting is more problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Qzt-HoIo4yks",
    "outputId": "8393b2ce-3c2c-402a-b144-0401936de137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "n_train = 1000\n",
    "x_train = x_train[0:n_train, :]\n",
    "y_train = y_train[0:n_train]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2JSWYGKjsPh"
   },
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(np.squeeze(img))\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDfQh4AfoBAH"
   },
   "source": [
    "Let's visualise several training examples - to do this we use the keras ImageDataGenerator. We rescale images by 1/255 to normalise them in the range (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "fuOz9BopjZPq",
    "outputId": "2c6fd799-b1b9-46fb-cd03-811bbd7cc247"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFR0IUZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1./255) \n",
    "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
    "sample_images, sample_labels = next(data_gen)\n",
    "plotImages(sample_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H8bStvJVoVlj"
   },
   "source": [
    "One regularisation method to deal with over-fitting is data augmentation. The image generator can apply various transformations to data - here we apply a random rotation of upto 20 degrees and visualise the same training example with different augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "iz28zlncmIiP",
    "outputId": "69a80c26-c6cb-4049-c356-6ee0384a5bdb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADZCAYAAADWkMBPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQc1x/1p5jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     rotation_range=20) \n",
    "data_gen = image_generator.flow(x_train, y_train, batch_size=32) \n",
    "augmented_images = [data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIE6-wlA3J4h"
   },
   "source": [
    "Define a basic CNN with 32 convolutional filters using a 3x3 kernel, followed by a dense fully connected layer of 128 units and an output layer of 10 units with softmax activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKolHZQUL8-4"
   },
   "outputs": [],
   "source": [
    "class BasicCNN(Model):\n",
    "  def __init__(self):\n",
    "    super(BasicCNN, self).__init__()\n",
    "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "    self.flatten = Flatten()\n",
    "    self.d1 = Dense(128, activation='relu')\n",
    "    self.d2 = Dense(10, activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.d1(x)\n",
    "    return self.d2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuhNDi134B2G"
   },
   "source": [
    "Main training routine - uses the more detailed Gradient Tape API to iterate over the dataset and update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZH8jdqKohiU"
   },
   "outputs": [],
   "source": [
    "def trainer(cls, train_image_generator, test_image_generator, \n",
    "            verbose=False, batch_size=32, max_epochs=5, \n",
    "            early_stopping=False, patience=5):\n",
    "  \n",
    "  model = cls()\n",
    "\n",
    "  train_data_gen = train_image_generator.flow(x_train, y_train, \n",
    "                                              batch_size=batch_size) \n",
    " \n",
    "  test_data_gen = test_image_generator.flow(x_test, y_test, \n",
    "                                              batch_size=batch_size) \n",
    "\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "  optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='train_accuracy')\n",
    "\n",
    "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='test_accuracy')\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      predictions = model(images, training=True)\n",
    "      loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "\n",
    "  @tf.function\n",
    "  def test_step(images, labels):\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "\n",
    "  final_test_loss = np.inf\n",
    "  counter = 0\n",
    "\n",
    "  for epoch in range(max_epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    batches = 0\n",
    "    for images, labels in train_data_gen:\n",
    "      train_step(images, labels)\n",
    "      batches += 1\n",
    "      if batches >= len(x_train) / batch_size:\n",
    "        break\n",
    "\n",
    "    batches = 0\n",
    "    for images, labels in test_data_gen:\n",
    "      test_step(images, labels)\n",
    "      batches += 1\n",
    "      if batches >= len(x_test) / batch_size:\n",
    "        break\n",
    "\n",
    "    if verbose:\n",
    "      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "      print(template.format(epoch+1,\n",
    "                            train_loss.result(),\n",
    "                            train_accuracy.result()*100,\n",
    "                            test_loss.result(),\n",
    "                            test_accuracy.result()*100))\n",
    "      \n",
    "    \n",
    "    if early_stopping:\n",
    "      if test_loss.result().numpy() < final_test_loss:\n",
    "        final_test_loss = test_loss.result().numpy() \n",
    "        counter = 0\n",
    "      counter += 1\n",
    "      if counter > patience:\n",
    "        break\n",
    "    else:\n",
    "      final_test_loss = test_loss.result().numpy()\n",
    "    \n",
    "  return final_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_HIq72IQMQXE"
   },
   "source": [
    "Baseline run with no early stopping and no augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "LkemC6SvTLOH",
    "outputId": "e84bbab4-806e-49a2-fbe5-a9bef9ba3ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0200583934783936, Accuracy: 68.80000305175781, Test Loss: 0.6541987657546997, Test Accuracy: 79.15999603271484\n",
      "Epoch 2, Loss: 0.30291905999183655, Accuracy: 91.5, Test Loss: 0.4383596181869507, Test Accuracy: 86.97999572753906\n",
      "Epoch 3, Loss: 0.15614180266857147, Accuracy: 95.30000305175781, Test Loss: 0.379736989736557, Test Accuracy: 88.55000305175781\n",
      "Epoch 4, Loss: 0.09504225105047226, Accuracy: 97.19999694824219, Test Loss: 0.4502171576023102, Test Accuracy: 87.12000274658203\n",
      "Epoch 5, Loss: 0.04762524366378784, Accuracy: 99.29999542236328, Test Loss: 0.3960731327533722, Test Accuracy: 88.7300033569336\n",
      "Epoch 6, Loss: 0.01493939757347107, Accuracy: 100.0, Test Loss: 0.40476301312446594, Test Accuracy: 89.06999969482422\n",
      "Epoch 7, Loss: 0.008234336972236633, Accuracy: 100.0, Test Loss: 0.43571463227272034, Test Accuracy: 88.84000396728516\n",
      "Epoch 8, Loss: 0.00462479330599308, Accuracy: 100.0, Test Loss: 0.41667428612709045, Test Accuracy: 89.45999908447266\n",
      "Epoch 9, Loss: 0.0034457710571587086, Accuracy: 100.0, Test Loss: 0.4351033866405487, Test Accuracy: 89.33000183105469\n",
      "Epoch 10, Loss: 0.0027447498869150877, Accuracy: 100.0, Test Loss: 0.43999528884887695, Test Accuracy: 89.38999938964844\n",
      "Epoch 11, Loss: 0.0022528665140271187, Accuracy: 100.0, Test Loss: 0.44323185086250305, Test Accuracy: 89.52000427246094\n",
      "Epoch 12, Loss: 0.001911725732497871, Accuracy: 100.0, Test Loss: 0.44741952419281006, Test Accuracy: 89.58000183105469\n",
      "Epoch 13, Loss: 0.0015891114016994834, Accuracy: 100.0, Test Loss: 0.45160478353500366, Test Accuracy: 89.56000518798828\n",
      "Epoch 14, Loss: 0.0013472676509991288, Accuracy: 100.0, Test Loss: 0.4601610004901886, Test Accuracy: 89.45999908447266\n",
      "Epoch 15, Loss: 0.001162495231255889, Accuracy: 100.0, Test Loss: 0.4613276422023773, Test Accuracy: 89.59000396728516\n",
      "Epoch 16, Loss: 0.0010446127271279693, Accuracy: 100.0, Test Loss: 0.4653335511684418, Test Accuracy: 89.51000213623047\n",
      "Epoch 17, Loss: 0.0009678736096248031, Accuracy: 100.0, Test Loss: 0.4706176519393921, Test Accuracy: 89.60000610351562\n",
      "Epoch 18, Loss: 0.0008144722087308764, Accuracy: 100.0, Test Loss: 0.47478458285331726, Test Accuracy: 89.6300048828125\n",
      "Epoch 19, Loss: 0.0007500156643800437, Accuracy: 100.0, Test Loss: 0.47701987624168396, Test Accuracy: 89.66000366210938\n",
      "Epoch 20, Loss: 0.0006649834685958922, Accuracy: 100.0, Test Loss: 0.48065853118896484, Test Accuracy: 89.66000366210938\n",
      "Final test loss: 0.48065853\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "final_test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, \n",
    "                          verbose=True, max_epochs=20)\n",
    "print('Final test loss:', final_test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_706EwYkOYg4"
   },
   "source": [
    "Run with early stopping and rotation augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "OGE77qkZMZlv",
    "outputId": "91e9d223-9a3e-40c4-e8c4-2e159011021e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0076160430908203, Accuracy: 67.19999694824219, Test Loss: 0.5000699758529663, Test Accuracy: 84.29000091552734\n",
      "Epoch 2, Loss: 0.43125128746032715, Accuracy: 87.0999984741211, Test Loss: 0.35363146662712097, Test Accuracy: 89.06999969482422\n",
      "Epoch 3, Loss: 0.2963999807834625, Accuracy: 89.30000305175781, Test Loss: 0.3345622420310974, Test Accuracy: 89.52999877929688\n",
      "Epoch 4, Loss: 0.2603868544101715, Accuracy: 91.29999542236328, Test Loss: 0.32859501242637634, Test Accuracy: 89.7800064086914\n",
      "Epoch 5, Loss: 0.19860294461250305, Accuracy: 94.4000015258789, Test Loss: 0.2892795205116272, Test Accuracy: 90.94000244140625\n",
      "Epoch 6, Loss: 0.1782345473766327, Accuracy: 94.5, Test Loss: 0.2752619981765747, Test Accuracy: 91.43000030517578\n",
      "Epoch 7, Loss: 0.13437680900096893, Accuracy: 96.4000015258789, Test Loss: 0.2472364455461502, Test Accuracy: 92.29999542236328\n",
      "Epoch 8, Loss: 0.1209961324930191, Accuracy: 97.0, Test Loss: 0.25273147225379944, Test Accuracy: 92.18999481201172\n",
      "Epoch 9, Loss: 0.12447181344032288, Accuracy: 96.5, Test Loss: 0.2622462511062622, Test Accuracy: 91.75\n",
      "Epoch 10, Loss: 0.0576138012111187, Accuracy: 98.4000015258789, Test Loss: 0.26570457220077515, Test Accuracy: 92.06999969482422\n",
      "Epoch 11, Loss: 0.06061906740069389, Accuracy: 98.29999542236328, Test Loss: 0.232929065823555, Test Accuracy: 93.22000122070312\n",
      "Epoch 12, Loss: 0.04623027145862579, Accuracy: 98.79999542236328, Test Loss: 0.2648938000202179, Test Accuracy: 92.54999542236328\n",
      "Epoch 13, Loss: 0.04380113258957863, Accuracy: 98.5999984741211, Test Loss: 0.24884618818759918, Test Accuracy: 92.95999908447266\n",
      "Epoch 14, Loss: 0.029856791719794273, Accuracy: 99.5, Test Loss: 0.2808802127838135, Test Accuracy: 92.06999969482422\n",
      "Epoch 15, Loss: 0.04031997174024582, Accuracy: 98.29999542236328, Test Loss: 0.2535262405872345, Test Accuracy: 92.72999572753906\n",
      "Epoch 16, Loss: 0.03225964307785034, Accuracy: 99.29999542236328, Test Loss: 0.2717909812927246, Test Accuracy: 92.18999481201172\n",
      "Final test loss: 0.23292907\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255, rotation_range=20) \n",
    "test_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "final_test_loss = trainer(BasicCNN, train_image_generator, test_image_generator, \n",
    "                          verbose=True, max_epochs=50, early_stopping=True)\n",
    "print('Final test loss:', final_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JULUcfS9Me_b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMKDGIaTM8dqAGYHnNcxlgd",
   "include_colab_link": true,
   "name": "regularisation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
