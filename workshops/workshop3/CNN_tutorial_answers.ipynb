{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MaggieLieu/MLiS2/blob/master/workshops/workshop3/CNN_tutorial_answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21YXWLJsBFF7"
   },
   "source": [
    "In this exercise we will train a convolutional neural network to classify MNIST characters. \n",
    "\n",
    "First we make sure we have GPU. Go to Edit $\\rightarrow$ Notebook Settings $\\rightarrow$ Hardware Accelerator $\\rightarrow$ GPU. \n",
    "\n",
    "You may have to restart the Runtime. Go to Runtime $\\rightarrow$ Restart runtime.\n",
    "\n",
    "Now we need to maksure we are using tensorflow v2 and not 1. You will need to restart the runtime again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5ODG2syG_Up"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# get packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBS1yUMVHQCE"
   },
   "source": [
    "Okay lets download a dataset. In the tensorflow_datasets package we have access to many well known machine learning datasets. See  \n",
    "https://www.tensorflow.org/datasets/catalog/overview  \n",
    "for the full list. Here we will download the MNIST dataset which contains images of handwritten numbers 0-9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RrIvk3urxQY"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1b45e5f5eb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mnist\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get mnist dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#split train test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "ds = tfds.load(name=\"mnist\", as_supervised = True) #get mnist dataset \n",
    "train, test = ds[\"train\"], ds[\"test\"] #split train test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4JhzJtaHNnr"
   },
   "source": [
    "The data are already in test and train sets and we can see how much data is in each. We won't necessarily use all of this data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aRnYUB1V4lr"
   },
   "outputs": [],
   "source": [
    "ntrain = len([image[0] for image in train])\n",
    "ntest = len([image[0] for image in test])\n",
    "\n",
    "print('Train sample: ', ntrain)\n",
    "print('Test sample: ', ntest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Y1fLoYoIPJ4"
   },
   "source": [
    "Let's take the first image from the train dataset and visualise it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEU3HcTh0NbM"
   },
   "outputs": [],
   "source": [
    "# take 1 image from train and convert to float64 and values 0-1\n",
    "data1 = train.map(\n",
    "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label) \n",
    ").take(1)\n",
    "\n",
    "#get first image data and label and plot it\n",
    "features, labels = iter(data1).next()\n",
    "print('image 1 shape: ', np.shape(features));\n",
    "plt.imshow(features[:,:,0], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szJwaVTyIl0c"
   },
   "source": [
    "You should see that we have an 28x28 grayscale image (1 channel) of the handwritten digit 8. \n",
    "\n",
    "To give you a feel for what the convolutional layer does, we are now going to apply filters to this image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyLcJFYtJfAF"
   },
   "source": [
    "Firstly we will apply a horizontal filter  \n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -1 & -1\n",
    "\\end{bmatrix}\n",
    "\n",
    "This filter enhances the horizontal features of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owjthOwpCJDr"
   },
   "outputs": [],
   "source": [
    "hor_filter = [[1,1,1],[0,0,0],[-1,-1,-1]]\n",
    "\n",
    "output = tf.nn.conv2d(\n",
    "      input=np.reshape(features, [1,28,28,1]), #batch, height, width, depth\n",
    "      filters=np.reshape(hor_filter, [3,3,1,1]), #height, width, in_channels, out_channels\n",
    "      strides=[1,1,1,1], \n",
    "      padding=\"VALID\")\n",
    "print('image shape: ', np.shape(output));\n",
    "plt.imshow(output[0,:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHHzkCI7KDM9"
   },
   "source": [
    "The filter has extracted the features of horizontal edges in the image. Note that the image size has shrunk from 28x28 to 26x26. \n",
    "\n",
    "Now lets try a vertical filter  \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1\n",
    "\\end{bmatrix}\n",
    "\n",
    "You should find that this filter extracts the vertical edges of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya0jt-bFFvab"
   },
   "outputs": [],
   "source": [
    "ver_filter = [[1,0,-1],[1,0,-1],[1,0,-1]]\n",
    "\n",
    "output = tf.nn.conv2d(\n",
    "      input=np.reshape(features, [1,28,28,1]),\n",
    "      filters=np.reshape(ver_filter, [3,3,1,1]),\n",
    "      strides=[1,1,1,1], #in batch, x, y, channel\n",
    "      padding=\"VALID\")\n",
    "print('image shape: ', np.shape(output));\n",
    "plt.imshow(output[0,:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fusvio_6cVz2"
   },
   "source": [
    "# Convolutional layer\n",
    "Now your task is to write your own function that takes an image, and a kernel to perform the convolution operation. Assume stride 1 and no padding.\n",
    "\n",
    "First do it with just one kernel and 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3y8g4JTeOVCU"
   },
   "outputs": [],
   "source": [
    "def unroll(F, ky, kx, ny, nx, oy, ox, stride):\n",
    "    uy = ox*oy\n",
    "    ux = nx*ny\n",
    "    \n",
    "    Fpadded = tf.pad(F, [[0, (nx-kx)],[0, (ny-ky)]] )\n",
    "    Fflat = tf.reshape(Fpadded,[ux])\n",
    "    \n",
    "    unrolledF = []\n",
    "    for iy in range(oy):\n",
    "        for ix in range(ox):\n",
    "            unrolled = tf.roll(Fflat, shift=(ix*stride+iy*(stride*nx)), axis=0)\n",
    "            unrolledF.append(unrolled)\n",
    "    out = tf.stack(unrolledF)\n",
    "    out = tf.reshape(out, [uy,ux])\n",
    "    return(out)\n",
    "\n",
    "def convolve2d(infeat, kernel, bias, padding, stride):\n",
    "    ky, kx = kernel.get_shape()\n",
    "    iy, ix = infeat.get_shape()\n",
    "    \n",
    "    #pad input \n",
    "    in_pad = tf.pad(infeat, [[padding,padding],[padding,padding]])\n",
    "    ny, nx = in_pad.get_shape()\n",
    "    \n",
    "    ox = (nx - kx) // stride + 1 # output size\n",
    "    oy = (ny - ky) // stride + 1 \n",
    "    \n",
    "    unrollF = unroll(kernel, ky, kx, ny, nx,oy,ox, stride=stride)\n",
    "    unrollI = tf.reshape(in_pad, [nx*ny])\n",
    "\n",
    "    convO = tf.tensordot(unrollF, unrollI, axes=1) #convolution\n",
    "    conv_reshaped = tf.reshape(convO, [ox,oy]) #reshape\n",
    "    outfeat = conv_reshaped + bias\n",
    "\n",
    "    return outfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDaWi-FUOVCX"
   },
   "outputs": [],
   "source": [
    "f1 = [[2,1],[2,1]]\n",
    "a = tf.constant([[1,2,3],[1,2,3],[1,2,3]], dtype=tf.float64)\n",
    "out = convolve2d(a, tf.constant(f1, dtype=tf.float64), bias=0, padding=1, stride=1)\n",
    "dif = [[ 1.,  4.,  7.,  6.],[ 2.,  8., 14., 12.],[ 2.,  8., 14., 12.], [ 1.,  4.,  7.,  6.]]\n",
    "print('Difference from truth: '); tf.print(tf.reduce_sum(dif-out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w2_b6aXiOVCZ"
   },
   "source": [
    "Now we want to generalise to 3 channels. Remember the number of channels in the image must equal the number of channels in the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPOVKEv6OVCa"
   },
   "outputs": [],
   "source": [
    "def unroll(F,  ky, kx, kz, ny, nx, nz, oy, ox, stride):\n",
    "    uy = ox*oy\n",
    "    ux = nx*ny*nz\n",
    "\n",
    "    #pad and flatten the filter, dimensions should be the [nx*ny*nz]\n",
    "    Fpadded = tf.pad(F, [[0, (ny-ky)],[0, (nx-kx)],[0,0]])\n",
    "    Fflat = tf.reshape(Fpadded,[nz*ny*nx])\n",
    "    unrolledF = [] \n",
    "    for iy in range(oy):\n",
    "        for ix in range(ox):\n",
    "            unroll = tf.roll(Fflat, shift=(ix*(stride*nz)+iy*(stride*nx*nz)), axis=0)\n",
    "            unrolledF.append(unroll)\n",
    "    out=tf.stack(unrolledF)\n",
    "    out=tf.reshape(out, [uy,ux])\n",
    "\n",
    "    return(out)\n",
    "\n",
    "def convolve2d(infeat, kernel, bias, padding, stride):\n",
    "    ky, kx, kz = kernel.get_shape()\n",
    "    iy, ix, iz = infeat.get_shape()\n",
    "    \n",
    "    #pad input \n",
    "    in_pad = tf.pad(infeat, [[padding,padding],[padding,padding],[0,0]])\n",
    "    ny, nx,nz = in_pad.get_shape()\n",
    "    \n",
    "    ox = (nx - kx) // stride + 1 # output size\n",
    "    oy = (ny - ky) // stride + 1 \n",
    "    \n",
    "    unrollI = tf.reshape(in_pad, [ny*nx*nz])\n",
    "    unrollF = unroll(kernel,ky, kx, kz, ny, nx,nz,oy,ox, stride=stride)\n",
    "    convO = tf.tensordot(unrollF, unrollI, axes=1) #convolution\n",
    "\n",
    "    conv_reshaped = tf.reshape(convO, [oy,ox]) #reshape\n",
    "\n",
    "    outfeat = conv_reshaped + bias\n",
    "\n",
    "    return outfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7f-Un0h-OVCc"
   },
   "outputs": [],
   "source": [
    "# 3 channel input\n",
    "a = tf.constant([[[5,2,3],[1,2,1],[1,2,3],[1,2,3]],\n",
    "                 [[3,2,3],[1,0,3],[1,2,1],[0,0,1]],\n",
    "                 [[1,1,1],[1,2,3],[0,2,3],[1,2,1]],\n",
    "                 [[1,0,3],[0,2,0],[1,2,3],[1,2,3]]], dtype=tf.float64)\n",
    "\n",
    "# 3 channel kernel\n",
    "f1 = [[2,1],[2,1]]\n",
    "f2 = [[3,1],[3,3]]\n",
    "f3 = [[3,2],[2,3]]\n",
    "f=np.dstack((f1,f2,f3))\n",
    "\n",
    "out = convolve2d(a, tf.constant(f, dtype=tf.float64), 0, 1, 1)\n",
    "dif =[[20., 32., 26., 30., 14.],[31., 58., 38., 39., 19.],[18., 51., 45., 35., 13.],[14., 31., 47., 50., 25.], [ 7., 13., 15., 26., 17.]]\n",
    "print('Difference from truth: '); tf.print(tf.reduce_sum(dif-out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xcn4xMiOVCf"
   },
   "source": [
    "Now lets generalise to multiple multichannel-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2cYRMd_OVCf"
   },
   "outputs": [],
   "source": [
    "def unroll(F,  kn, ky, kx, kz, ny, nx, nz, oy, ox, stride):\n",
    "    uy = ox*oy\n",
    "    ux = nx*ny*nz\n",
    "\n",
    "    #pad and flatten the filter, dimensions should be the [nx*ny*nz]\n",
    "    Fpadded = tf.pad(F, [[0,0],[0, (ny-ky)],[0, (nx-kx)],[0,0]])\n",
    "    Fflat = tf.reshape(Fpadded,[kn, nz*ny*nx])\n",
    "    unrolledF = [] \n",
    "    for iy in range(oy):\n",
    "        for ix in range(ox):\n",
    "            unroll = tf.roll(Fflat, shift=(ix*(stride*nz)+iy*(stride*nx*nz)), axis=1)\n",
    "            unrolledF.append(unroll)\n",
    "    out=tf.stack(unrolledF, axis=1)\n",
    "    out=tf.reshape(out, [kn, uy,ux])\n",
    "\n",
    "    return(out)\n",
    "\n",
    "def convolve2d(infeat, kernel, bias, padding, stride):\n",
    "    kn, ky, kx, kz = kernel.get_shape()\n",
    "    iy, ix, iz = infeat.get_shape()\n",
    "    \n",
    "    #pad input \n",
    "    in_pad = tf.pad(infeat, [[padding,padding],[padding,padding],[0,0]])\n",
    "    ny, nx,nz = in_pad.get_shape()\n",
    "    \n",
    "    ox = (nx - kx) // stride + 1 # output size\n",
    "    oy = (ny - ky) // stride + 1 \n",
    "    \n",
    "    unrollI = tf.reshape(in_pad, [ny*nx*nz])\n",
    "    unrollF = unroll(kernel, kn, ky, kx, kz, ny, nx,nz,oy,ox, stride=stride)\n",
    "\n",
    "    convO = tf.tensordot(unrollF, unrollI, axes=1) #convolution\n",
    "    conv_reshaped = tf.reshape(tf.transpose(convO), [oy,ox,kn]) #reshape\n",
    "\n",
    "    outfeat = conv_reshaped + bias\n",
    "\n",
    "    return outfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM0UnQpPOVCj"
   },
   "outputs": [],
   "source": [
    "# 4x3 channel kernels\n",
    "f1 = [[2,1],[2,1]]\n",
    "f2 = [[3,1],[3,3]]\n",
    "f3 = [[3,2],[2,3]]\n",
    "k1 = np.dstack((f1,f1,f1))\n",
    "k2 = np.dstack((f2,f2,f2))\n",
    "k3 = np.dstack((f3,f3,f3))\n",
    "k4 = np.dstack((f1,f2,f3))\n",
    "\n",
    "out = convolve2d(a, tf.constant([k1,k2,k3,k4], dtype=tf.float64), 0, 1, 1)\n",
    "\n",
    "dif =[[[10., 30., 30., 20.],\n",
    "        [24., 42., 32., 32.],\n",
    "        [14., 30., 26., 26.],\n",
    "        [18., 36., 30., 30.],\n",
    "        [12., 18., 12., 14.]],\n",
    "\n",
    "       [[18., 34., 44., 31.],\n",
    "        [44., 70., 66., 58.],\n",
    "        [26., 42., 44., 38.],\n",
    "        [27., 39., 41., 39.],\n",
    "        [14., 21., 20., 19.]],\n",
    "\n",
    "       [[11., 17., 25., 18.],\n",
    "        [32., 55., 56., 51.],\n",
    "        [29., 49., 47., 45.],\n",
    "        [23., 40., 36., 35.],\n",
    "        [10., 15., 11., 13.]],\n",
    "\n",
    "       [[ 7., 15., 18., 14.],\n",
    "        [22., 33., 35., 31.],\n",
    "        [27., 47., 50., 47.],\n",
    "        [32., 55., 53., 50.],\n",
    "        [20., 30., 24., 25.]],\n",
    "\n",
    "       [[ 4.,  4.,  8.,  7.],\n",
    "        [10., 14., 16., 13.],\n",
    "        [10., 12., 18., 15.],\n",
    "        [18., 24., 30., 26.],\n",
    "        [12., 18., 18., 17.]]]\n",
    "\n",
    "print('Difference from truth: '); tf.print(tf.reduce_sum(dif-out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RIrbw6mYhXE"
   },
   "source": [
    "Now batch images:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSiqt7ivYgAR"
   },
   "outputs": [],
   "source": [
    "def unroll(F,  kn, ky, kx, kz, nn, ny, nx, nz, oy, ox, stride):\n",
    "    uy = ox*oy\n",
    "    ux = nx*ny*nz\n",
    "\n",
    "    #pad and flatten the filter\n",
    "    Fpadded = tf.pad(F, [[0,0],[0, (ny-ky)],[0, (nx-kx)],[0,0]])\n",
    "    Fflat = tf.reshape(Fpadded,[kn, nz*ny*nx])\n",
    "    unrolledF = [] \n",
    "    for iy in range(oy):\n",
    "        for ix in range(ox):\n",
    "            unroll = tf.roll(Fflat, shift=(ix*(stride*nz)+iy*(stride*nx*nz)), axis=1)\n",
    "            unrolledF.append(unroll)\n",
    "    out=tf.stack(unrolledF, axis=1)\n",
    "    out=tf.reshape(out, [kn, uy,ux])\n",
    "\n",
    "    return(out)\n",
    "\n",
    "def convolve2d(infeat, kernel, bias, padding, stride):\n",
    "    kn, ky, kx, kz = kernel.get_shape()\n",
    "    inn,iy, ix, iz = infeat.get_shape()\n",
    "    \n",
    "    #pad input \n",
    "    in_pad = tf.pad(infeat, [[0,0],[padding,padding],[padding,padding],[0,0]])\n",
    "    nn, ny, nx,nz = in_pad.get_shape()\n",
    "    \n",
    "    ox = (nx - kx) // stride + 1 # output size\n",
    "    oy = (ny - ky) // stride + 1 \n",
    "    \n",
    "    unrollI = tf.reshape(in_pad, [nn, ny*nx*nz])\n",
    "    unrollF = unroll(kernel, kn, ky, kx, kz, nn, ny, nx,nz,oy,ox, stride=stride)\n",
    "\n",
    "    convO = tf.tensordot(unrollF, unrollI, axes=[[2],[1]]) #convolution\n",
    "    conv_reshaped = tf.reshape(tf.transpose(convO), [nn,oy,ox,kn]) #reshape\n",
    "    outfeat = conv_reshaped + bias\n",
    "\n",
    "    return outfeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkQoOgpxOVCr"
   },
   "source": [
    "Check your functions work by applying the convolution layer with the vertical filter on the first image on MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzjdbn0eOVCr"
   },
   "outputs": [],
   "source": [
    "x = tf.constant(np.reshape(features[:,:,0],(1,28,28,1)))\n",
    "b = tf.constant(np.reshape(ver_filter, (1,3,3,1)), dtype=tf.float64)\n",
    "np.shape(b)\n",
    "out=convolve2d(x,b,0, padding=0, stride=1);\n",
    "out.get_shape()\n",
    "plt.imshow(out[0,:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5pVRsQTcj1t"
   },
   "source": [
    "Compare the convolution with the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pgRldkmkOVCu"
   },
   "outputs": [],
   "source": [
    "difs = out[0,:,:,0] - output[0,:,:,0]\n",
    "plt.imshow(difs, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWKMUfwkOVCx"
   },
   "outputs": [],
   "source": [
    "plt.hist(difs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vw6SN0dgOVCz"
   },
   "source": [
    "You might see some differences but these are due to rounding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Cr5VUWpOVC0"
   },
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZ0jsVz0OVC0"
   },
   "source": [
    "The convolution operation is linear. To make it non-linear we need to add an activation function. Here your task is to write a ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMboXROmOVC1"
   },
   "outputs": [],
   "source": [
    "def ReLU(infeat):\n",
    "    return tf.maximum(infeat, tf.zeros_like(infeat))\n",
    "    \n",
    "relu0 = ReLU(out)\n",
    "plt.imshow(relu0[0,:,:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kbp9Vh88OVC3"
   },
   "source": [
    "Compare it to the built in function it should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfRRVdmxOVC4"
   },
   "outputs": [],
   "source": [
    "true_relu0 = tf.nn.relu(out)\n",
    "plt.imshow(true_relu0[0,:,:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egbO3wf1ctMs"
   },
   "source": [
    "# Pooling layer \n",
    "Write a function to do pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI93t2tmRm5H"
   },
   "outputs": [],
   "source": [
    "def pooling(infeat, ky, kx,kz, padding, stride, pooling_type):\n",
    "    in_pad = tf.pad(infeat,[[0,0],[padding,padding],[padding,padding],[0,0]]) #pad the input\n",
    "    \n",
    "    nn, ny, nx, nz = in_pad.get_shape()\n",
    "    kn = nn\n",
    "    \n",
    "    ox = (nx - kx) // stride + 1 # output size\n",
    "    oy = (ny - ky) // stride + 1 \n",
    "    oz = nz\n",
    "\n",
    "    #unroll to get indices to pool, here the number of filters is the input number of channels and the number kernel channels=1 \n",
    "    unrolledF = unroll(tf.ones([kn,ky,kx,kz]), kn, ky, kx, kz, nn, ny, nx, nz, oy, ox, stride)\n",
    "\n",
    "    #multiply unrolled kernel with input to get values to pool\n",
    "    flatin = tf.reshape(in_pad,[nn,nz*nx*ny])\n",
    "    tilein = tf.tile(flatin, [1,ox*oy])\n",
    "    test = tf.reshape(tilein, [nn, ox*oy, nz*nx*ny])\n",
    "    pools = tf.boolean_mask(test, unrolledF[:,:,:])\n",
    "    tileout = tf.reshape(pools, [nn,ox*oy,kx*ky,oz])\n",
    "    \n",
    "    #apply max or mean pooling \n",
    "    if(pooling_type=='MAX'):\n",
    "        out = tf.reduce_max(tileout,axis=2)\n",
    "    elif(pooling_type=='AVG'):\n",
    "        out = tf.reduce_mean(tileout,axis=2)\n",
    "    return tf.reshape(out, [nn,oy,ox,oz])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdn7hMGPOVC-"
   },
   "source": [
    "Apply the pooling layer to the raw image with a 5x5 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9IrKgbeOVC-"
   },
   "outputs": [],
   "source": [
    "pooled = pooling(relu0,5,5,1,0,1, 'AVG')\n",
    "plt.imshow(pooled[0,:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ypG0fTDiOVDB"
   },
   "source": [
    "You should have got something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxercJk3vBWE"
   },
   "outputs": [],
   "source": [
    "n, y,x,z = np.shape(relu0)\n",
    "true_pooled = tf.nn.pool(\n",
    "    input = np.reshape(relu0, [1,y,x,1]),\n",
    "    window_shape = [5,5],\n",
    "    strides=[1,1],\n",
    "    pooling_type = 'AVG',\n",
    "    padding = 'VALID'\n",
    ")\n",
    "plt.imshow(true_pooled[0,:,:,0],cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9IEHp9FvFHf"
   },
   "source": [
    "How does Max pool and average pool compare?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EK5jN6wgvP0f"
   },
   "outputs": [],
   "source": [
    "pooled = pooling(relu0,5,5,1,0,1, 'MAX')\n",
    "plt.imshow(pooled[0,:,:,0], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8bbc_nFvPdF"
   },
   "source": [
    "What happens when you apply the activation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikiGyo4Mvh8-"
   },
   "outputs": [],
   "source": [
    "relu1 = ReLU(pooled)\n",
    "plt.imshow(relu1[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdQCW0PQOVDM"
   },
   "source": [
    "# Fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGJK-C2sOVDM"
   },
   "source": [
    "The fully connected layer, is a layer that has no shared weights. In this part you need to write a function for the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ta-CO2G2OVDN"
   },
   "outputs": [],
   "source": [
    "def fully_connected(infeat, kernel, bias):\n",
    "    nn,ny, nx, nz = infeat.get_shape()\n",
    "    kn, ky, kx, kz = kernel.get_shape()\n",
    "\n",
    "    flatin = tf.reshape(infeat, [nn, ny*nx*nz])\n",
    "    flatk = tf.reshape(kernel, [kn, ky*kx*kz])\n",
    "    out =tf.reshape(tf.transpose(tf.tensordot(flatk, flatin, axes=[1,1])) + bias, [nn,1,1,kn])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yqgvd-jOVDP"
   },
   "source": [
    "Now test the fully connected layer works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5U2BTxjOVDQ"
   },
   "outputs": [],
   "source": [
    "kn = 2\n",
    "imn = 1\n",
    "k = np.random.randint(low=0, high=2,size=[kn,3,3,1])\n",
    "\n",
    "b = tf.zeros([imn,kn],dtype=tf.float64)\n",
    "\n",
    "im = np.random.randint(low=0, high=5,size=[imn,3,3,1])\n",
    "fully_connected(tf.constant(im,dtype=tf.float64),tf.constant(k,dtype=tf.float64), b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eg9LuSUyOVDS"
   },
   "source": [
    "Actually you should find that the fully connected layer is the same as the conv2D layer using a kernel size the same as the input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VyeLazNOVDT"
   },
   "outputs": [],
   "source": [
    "convolve2d(tf.constant(im,dtype=tf.float64),tf.constant(k,dtype=tf.float64),0, padding=0, stride=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6gzt7G-OVDX"
   },
   "source": [
    "apply the fully connected layer we just created to the output of the ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QvNXOq8OOVDY"
   },
   "outputs": [],
   "source": [
    "nn,ny,nx,nz = relu1.get_shape()\n",
    "outsz = 2\n",
    "\n",
    "#kernel size has dimensions [input width, input height,output size]\n",
    "ink = tf.random.normal([outsz, ny, nx, nz], dtype=tf.float64)\n",
    "\n",
    "#bias size has dimensions [output size]\n",
    "inb = tf.zeros([nn,outsz],dtype=tf.float64)\n",
    "\n",
    "outim = fully_connected(relu1, ink, inb)\n",
    "tf.print(outim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dp5sMj-aOVDa"
   },
   "source": [
    "after a fully connected layer you must add non-linearity via an activation function. Since its not yet the last layer we can add ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bs0IzYnROVDb"
   },
   "outputs": [],
   "source": [
    "relu2 = ReLU(outim)\n",
    "tf.print(relu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YuxEMM_KOVDd"
   },
   "source": [
    "# Softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34FQC2P3OVDd"
   },
   "source": [
    "For the last layer, you probably want to use softmax activation. So here you should write a function to do softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57xead0iOVDe"
   },
   "outputs": [],
   "source": [
    "def softmax(infeat):\n",
    "    innorm = infeat - tf.reduce_max(infeat) #normalise the input values to prevent blow up\n",
    "    inexp = tf.exp(innorm) \n",
    "    tot = tf.reduce_sum(inexp) #normalisation factor\n",
    "    \n",
    "    return inexp / tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f3RU_DeqOVDh"
   },
   "source": [
    "Add the final fully connected layer and softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K246H4vcOVDj"
   },
   "outputs": [],
   "source": [
    "nn,ny,nx,nz= relu2.get_shape()\n",
    "outsz = 3\n",
    "\n",
    "#kernel size has dimensions [output size, input width, input height]\n",
    "ink = tf.random.normal([outsz,ny,nx,nz], dtype=tf.float64)\n",
    "\n",
    "#bias size has dimensions [output size, 1]\n",
    "inb = tf.zeros([nn,outsz],dtype=tf.float64)\n",
    "\n",
    "outim = fully_connected(relu2, ink, inb)\n",
    "out = softmax(outim)\n",
    "tf.print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIHrros4OVDm"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, t):\n",
    "    return tf.reduce_mean(tf.losses.categorical_crossentropy( t,  y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irhlI8QCOVDu"
   },
   "source": [
    "# Build the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaOD4CHxOVDv"
   },
   "source": [
    "Now you have all the functions you need to build your neural network so first you need to set up all the variables and their dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbLsGS5XOVDv"
   },
   "outputs": [],
   "source": [
    "# First initialise variables \n",
    "f1n, f1y, f1x, f1z = 10, 3, 3, 1\n",
    "W1 = tf.Variable(tf.random.normal([f1n, f1y, f1x, f1z], stddev=0.01, dtype=tf.float64 ), name='W1')\n",
    "b1 = tf.Variable(tf.zeros([f1n], dtype=tf.float64 ), name='b1')\n",
    "\n",
    "f2n, f2y, f2x, f2z = 10, 3, 3, 10\n",
    "W2 = tf.Variable(tf.random.normal([f2n, f2y, f2x, f2z], stddev=0.01, dtype=tf.float64 ), name='W2')\n",
    "b2 = tf.Variable(tf.zeros([f2n], dtype=tf.float64 ), name='b2')\n",
    "\n",
    "f3n, f3y, f3x, f3z = 50, 20, 20, 10\n",
    "W3 = tf.Variable(tf.random.normal([f3n, f3y, f3x, f3z], stddev=0.01, dtype=tf.float64 ), name='W3')\n",
    "b3 = tf.Variable(tf.zeros([f3n], dtype=tf.float64 ), name='b3')\n",
    "\n",
    "f4n, f4y, f4x, f4z = 10, 1, 1, 50\n",
    "W4 = tf.Variable(tf.random.normal([f4n, f4y, f4x, f4z], stddev=0.01, dtype=tf.float64 ), name='W4')\n",
    "b4 = tf.Variable(tf.zeros([f4n], dtype=tf.float64 ), name='b4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVR-wMIIOVDx"
   },
   "source": [
    "Next set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AGaEwD_-OVDx"
   },
   "outputs": [],
   "source": [
    "def model( X ) :\n",
    "    X = tf.cast( X , dtype=tf.float64 )\n",
    "    \n",
    "    #LAYER 1\n",
    "    conv1 = convolve2d(X, W1, b1, padding=0, stride=1);\n",
    "    conv1act = ReLU(conv1)\n",
    "    pool1 = pooling(conv1act, 3, 3, 10, 0, 1, 'MAX') #out[24,24,10]\n",
    "    \n",
    "    #LAYER 2\n",
    "    conv2 =  convolve2d(pool1, W2, b2, padding=0, stride=1);\n",
    "    conv2act = ReLU(conv2) \n",
    "    pool2 = pooling(conv2act, 3, 3,10, 0, 1, 'MAX') #out[20,20,10]\n",
    "\n",
    "    #LAYER 3\n",
    "    fc1 = fully_connected(pool2, W3, b3)\n",
    "    fc1act = ReLU(fc1) #out[1,1,50]\n",
    "\n",
    "    #LAYER 4\n",
    "    fc2 = fully_connected(fc1act, W4, b4)\n",
    "    fc2act = softmax(fc2) #out[1,1,10]\n",
    "    out =  out = tf.squeeze(fc2act, axis=(1,2)) #out [10]\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nHKnZ5POVD0"
   },
   "source": [
    "Train the model on MNIST training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMTVmE4hOVD1"
   },
   "outputs": [],
   "source": [
    "LR = 0.001 #learning rate\n",
    "optimizer = tf.optimizers.Adam(LR) #adam optimiser\n",
    "\n",
    "def train_step( model, X , Y ):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = cross_entropy_loss( model( X ), Y)\n",
    "    grads = tape.gradient( current_loss , [W1,b1,W2,b2,W3,b3,W4,b4] )\n",
    "    optimizer.apply_gradients( zip( grads , [W1,b1,W2,b2,W3,b3,W4,b4]) )\n",
    "\n",
    "    return(current_loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iV6ydOffOVD2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = train.map(\n",
    "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label) \n",
    ").take(200\n",
    ").batch(10)\n",
    "\n",
    "nepoch = 200\n",
    "\n",
    "for epoch in range(nepoch):\n",
    "    for features in dataset:\n",
    "        image, label = features[0] , features[1]\n",
    "        loss = train_step( model , image , tf.one_hot( label , depth=10 ) ) #run training, with labels reformated to size [batch, nclass]\n",
    "    print('epoch: ',epoch, ', loss:', loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoLYoIyXOVD4"
   },
   "source": [
    "Apply on the model to the MNIST test data and compare with truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_90htxcOVD4"
   },
   "outputs": [],
   "source": [
    "testset = test.map(\n",
    "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label) \n",
    ").take(20\n",
    ")\n",
    "\n",
    "for features in testset:\n",
    "    image, label = features[0] , features[1]\n",
    "    pred = model(image)\n",
    "    pred_label = tf.argmax(pred, axis=2)\n",
    "    tf.print('predicted: ', pred_label, '  - true: ', label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cPshz8qOVD6"
   },
   "source": [
    "# Additional work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FrMOM34LOVD7"
   },
   "source": [
    "- You can log and plot the training loss to see how well the network is doing during training.\n",
    "\n",
    "- Try to see if you can improve the performance of the network, these can be done by introducing batches for training, augmentations etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bohU3OejA7Sb"
   },
   "outputs": [],
   "source": [
    "train = train.map(\n",
    "    lambda image, label: (tf.image.convert_image_dtype(image, tf.float64), label) #convert images to float64 and 0-1\n",
    ").cache( #cache results as those can be re-used after each repeat\n",
    ").map(\n",
    "    lambda image, label: (tf.image.random_contrast(image, lower=0.0, upper=1.0), label) #random contrast\n",
    ").take(500 # take 500 images\n",
    ").batch(10 # split into batches of 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5D9xhoSJQBtM"
   },
   "source": [
    "# Extra reading\n",
    "\n",
    "- deconvolution layers:  \n",
    "https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0\n",
    "\n",
    "- A guide to convolutional arithmetic in deep learning, Dumoulin & Visin\n",
    ":  \n",
    "https://arxiv.org/abs/1603.07285  \n",
    "\n",
    "- Fully convolutional networks for semantic segmentation, Long et al:\n",
    "https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
    "\n",
    "- Deconvolution & checkerboard artefacts, Odena et al:\n",
    "https://distill.pub/2016/deconv-checkerboard/\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CNN_tutorial_answers.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
